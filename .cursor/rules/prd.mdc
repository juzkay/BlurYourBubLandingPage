---
alwaysApply: true
---

# iOS Photo Blur App - Product Requirements Document

## Project Overview
A minimal iOS app that allows parents to selectively blur areas of photos (particularly children's faces) before sharing on social media. The app prioritizes simplicity, reliability, and industry-standard blur quality.

## Target User
Parents who want to protect their children's privacy on social media while still sharing family moments.

## Core Requirements

### MVP Features (Phase 1)
1. **Photo Selection**: Import photos from camera roll
2. **Drawing Interface**: Touch-based drawing to mark blur areas
3. **Selective Blur**: Apply professional-quality blur to drawn areas only
4. **Export/Share**: Save or share processed images
5. **Simple UI**: Clean, modern interface requiring minimal learning

### Core Features (Phase 1.5)
6. **Video Selection**: Import videos from camera roll
7. **Automatic Face Detection**: Use Vision framework to detect faces in videos
8. **Video Face Blur**: Apply real-time blur to detected faces throughout video
9. **Video Export**: Save processed videos to camera roll

### Technical Requirements
- **Platform**: iOS 15.0+
- **Framework**: SwiftUI + UIKit (for photo picker)
- **Blur Quality**: Industry-standard using Core Image filters
- **Performance**: Real-time drawing feedback, sub-2-second blur processing
- **File Support**: JPEG, HEIC, PNG from photo library; MP4, MOV from video library
- **Face Detection**: Vision framework for automatic face recognition in videos
- **Video Processing**: AVFoundation for video manipulation and export

## File Structure & Architecture

```
PhotoBlurApp/
├── PhotoBlurApp.xcodeproj
├── PhotoBlurApp/
│   ├── App/
│   │   ├── PhotoBlurApp.swift                 # Main App entry point
│   │   └── Info.plist                         # App configuration
│   │
│   ├── Views/
│   │   ├── ContentView.swift                  # Main coordinator view
│   │   ├── MediaSelectionView.swift           # Photo/Video selection screen
│   │   ├── EmptyStateView.swift              # Welcome/no media state
│   │   ├── PhotoEditView.swift               # Photo display + drawing overlay
│   │   ├── VideoEditView.swift               # Video display + face detection
│   │   ├── DrawingOverlay.swift              # Touch drawing interface
│   │   ├── VideoControlsView.swift           # Video playback controls
│   │   └── BottomControlsView.swift          # Action buttons
│   │
│   ├── Models/
│   │   ├── BlurPath.swift                    # Data model for drawn paths
│   │   ├── MediaType.swift                   # Enum for photo/video types
│   │   └── FaceDetectionResult.swift         # Face detection data
│   │
│   ├── Services/
│   │   ├── BlurProcessor.swift               # Core blur processing logic
│   │   ├── VideoFaceDetector.swift           # Vision-based face detection
│   │   ├── VideoBlurProcessor.swift          # Video blur processing
│   │   ├── MediaPicker.swift                 # Photo/Video library integration
│   │   └── VideoExporter.swift               # Video export functionality
│   │
│   ├── Utils/
│   │   ├── ShareSheet.swift                  # iOS share functionality
│   │   ├── PermissionsManager.swift          # Camera roll permissions
│   │   └── Extensions.swift                  # Utility extensions
│   │
│   └── Resources/
│       ├── Assets.xcassets                   # App icons, colors
│       └── Launch Screen.storyboard          # Launch screen
│
└── README.md                                 # Setup instructions
```

## Component Specifications

### 1. ContentView.swift
**Purpose**: Main app coordinator and state management
**Responsibilities**:
- Manage app-wide state (selected media, media type, blur paths, processed content)
- Handle view transitions and modal presentations
- Coordinate between photo and video editing modes

### 2. MediaSelectionView.swift
**Purpose**: Choose between photo and video processing
**Requirements**:
- Segmented control or tab interface for photo/video selection
- Launch appropriate media picker based on selection
- Clear visual distinction between modes

### 3. EmptyStateView.swift
**Purpose**: Initial welcome screen when no media is selected
**Requirements**:
- Clear call-to-action to select photo or video
- Modern, friendly design with system icons
- Buttons for both photo and video selection

### 4. PhotoEditView.swift
**Purpose**: Display selected photo with drawing capabilities
**Requirements**:
- Aspect-fit image display with proper scaling
- Overlay drawing interface when in drawing mode
- Accurate touch-to-image coordinate mapping
- Visual feedback for drawing areas (red lines)

### 5. VideoEditView.swift
**Purpose**: Display video with face detection and blur controls
**Requirements**:
- Video player with standard playback controls
- Real-time face detection overlay during playback
- Visual indicators for detected faces (colored rectangles)
- Toggle for automatic face blur on/off
- Preview of blur effect in real-time

### 6. DrawingOverlay.swift
**Purpose**: Handle touch input for marking blur areas (photos only)
**Technical Requirements**:
- Canvas-based drawing with smooth line rendering
- Convert screen coordinates to image pixel coordinates
- Real-time path visualization
- Support both single taps and continuous drawing

### 7. VideoControlsView.swift
**Purpose**: Video-specific playback and processing controls
**Requirements**:
- Play/pause button
- Scrub timeline for video navigation
- Face detection toggle
- Processing progress indicator
- Export button when processing complete

### 8. VideoFaceDetector.swift
**Purpose**: Detect faces in video frames using Vision framework
**Technical Requirements**:
- Use VNDetectFaceRectanglesRequest for face detection
- Process video frames at 30fps or video's native framerate
- Track faces across frames for consistent blur application
- Handle multiple faces per frame
- Optimize for real-time performance

### 9. VideoBlurProcessor.swift
**Purpose**: Apply blur effects to detected faces in video
**Technical Requirements**:
- Use AVVideoComposition for real-time video effects
- Apply Gaussian blur to face regions only
- Maintain blur consistency across frames
- Handle face tracking and movement
- Export processed video maintaining original quality and audio

### 10. VideoExporter.swift
**Purpose**: Export processed videos to camera roll
**Technical Requirements**:
- Use AVAssetExportSession for high-quality export
- Maintain original video resolution and framerate
- Preserve audio track
- Show export progress to user
- Handle export errors gracefully

## User Flow

### Photo Processing Flow
```
App Launch
    ↓
Media Selection (Photo/Video)
    ↓
Select Photo → Photo Edit View
    ↓
Toggle Drawing Mode → Draw on Image
    ↓
Apply Blur → Processed Image
    ↓
Share/Save → Export Options
```

### Video Processing Flow
```
App Launch
    ↓
Media Selection (Photo/Video)
    ↓
Select Video → Video Edit View
    ↓
Play Video → Faces Auto-Detected
    ↓
Toggle Face Blur → Preview Effect
    ↓
Process Video → Export Progress
    ↓
Share/Save → Export Options
```

## Technical Implementation Guidelines

### Drawing System
- Use SwiftUI Canvas for smooth drawing
- Store paths as arrays of CGPoints in image coordinates
- Convert between screen and image coordinates accurately
- Provide visual feedback with semi-transparent red overlay

### Blur Processing (Photos)
- Primary: Core Image CIFilter.gaussianBlur()
- Fallback: Custom pixel-level blending if CI fails
- Create binary masks from drawn paths (white = blur, black = original)
- Use brush width of 40-60 pixels for adequate coverage

### State Management
- Single source of truth in ContentView for both photos and videos
- Separate state management for photo editing vs video processing
- Pass state down via @Binding
- Clear state on media selection/reset
- Handle video playback state and face detection results

### Error Handling
- Graceful fallbacks for image/video processing failures
- User-friendly error messages for permission issues
- Handle video processing timeouts and memory constraints
- Maintain app stability with proper optionals and guards
- Clear error states for face detection failures

## UI/UX Requirements

### Design Principles
- **Minimal**: Focus on core functionality only
- **Intuitive**: No tutorials needed, obvious interactions
- **Modern**: Follow iOS design guidelines
- **Accessible**: Proper contrast, touch targets, labels

### Visual Style
- Clean backgrounds (white/light gray)
- System blue for primary actions
- Red overlay for drawing areas (semi-transparent)
- Rounded corners and modern button styles
- SF Symbols for icons

### Interaction Patterns
- Tap to select media type (photo/video)
- Tap to select specific media from library
- **Photos**: Toggle to enter drawing mode, draw directly on image
- **Videos**: Automatic face detection with visual overlay
- Single tap to apply blur/process video
- Standard iOS share sheet for export
- Video scrubbing and playback controls

## Future Enhancements (Post-MVP)

### Phase 2 Features
- **Photos**: Automatic face detection and blur for photos
- Adjustable blur intensity slider
- Different blur types (pixelate, mosaic)
- Undo/redo drawing actions
- Multiple brush sizes
- **Videos**: Manual face selection override
- Video trimming before processing
- Batch processing multiple videos

### Phase 3 Features
- Batch processing multiple photos/videos
- Custom blur shapes (circles, rectangles)
- Save drawing templates
- In-app photo/video capture
- Advanced face tracking and recognition
- Cloud processing for large videos

## Performance Requirements
- App launch: < 2 seconds
- Photo loading: < 1 second
- Video loading: < 3 seconds
- Drawing response: Real-time (60fps)
- Photo blur processing: < 2 seconds for 12MP images
- Video face detection: Real-time at 30fps
- Video processing: < 5 seconds per minute of 1080p video
- Memory usage: < 200MB for typical use, < 500MB for 4K video processing

## Quality Assurance

### Testing Requirements
- Test on various iPhone screen sizes and orientations
- Verify blur quality matches industry standards for both photos and videos
- Ensure drawing accuracy across different image orientations
- Test face detection accuracy across different lighting conditions and angles
- Validate video processing maintains audio sync and quality
- Test memory management with large images and 4K videos
- Validate share functionality across social platforms
- Test video export formats compatibility

### Code Quality Standards
- Swift 5.0+ with modern syntax
- SwiftUI best practices
- Proper error handling with do-catch blocks
- Memory-safe Core Image processing
- Clean separation of concerns

## Deployment Requirements
- iOS 15.0+ minimum deployment target
- Xcode 14+ for development
- No external dependencies (use system frameworks only)
- Proper Info.plist permissions for photo and video access
- Camera roll write permissions for video export

## Success Metrics
- **Functional**: Blur processing works 99.9% of the time for photos and videos
- **Performance**: Sub-2-second photo processing, sub-5-second per minute video processing
- **Accuracy**: Face detection accuracy >95% in good lighting conditions
- **Usability**: Users can complete blur task without instructions
- **Quality**: Blur effect indistinguishable from professional tools
- **Reliability**: Video export success rate >98%

## Development Notes for Cursor IDE

### Key Implementation Points
1. **Coordinate Mapping**: Critical to get drawing alignment correct for photos
2. **Face Detection**: Use Vision framework with VNDetectFaceRectanglesRequest for real-time detection
3. **Video Processing**: Leverage AVVideoComposition for efficient video blur effects
4. **Image Processing**: Use Core Image for quality, fallback for reliability  
5. **State Management**: Keep it simple with clear data flow between photo/video modes
6. **Error Handling**: Fail gracefully, never crash, especially during video processing
7. **Performance**: Profile both image and video processing on device
8. **Memory Management**: Critical for video processing - use autoreleasepool for frame processing

### Common Pitfalls to Avoid
- Screen vs image coordinate confusion in photo editing
- Memory leaks during video processing (use autoreleasepool)
- Force unwrapping optionals in image/video processing
- Complex state management between photo and video modes
- Over-engineering the drawing system
- Not handling video orientation changes
- Face detection performance issues on older devices
- Video export quality degradation
- Audio sync issues during video processing

### Required Permissions (Info.plist)
```xml
<key>NSPhotoLibraryUsageDescription</key>
<string>This app needs access to photos and videos to blur sensitive areas</string>

<key>NSPhotoLibraryAddUsageDescription</key>
<string>This app needs permission to save processed videos to your photo library</string>

<key>NSCameraUsageDescription</key>
<string>This app needs camera access for future photo/video capture features</string>
```

### Required Frameworks
- **SwiftUI**: Modern UI framework
- **AVFoundation**: Video processing and export
- **Vision**: Face detection in videos
- **Core Image**: Image and video blur effects
- **Photos**: Photo library access
- **PhotosUI**: Modern photo/video picker
# iOS Photo Blur App - Product Requirements Document

## Project Overview
A minimal iOS app that allows parents to selectively blur areas of photos (particularly children's faces) before sharing on social media. The app prioritizes simplicity, reliability, and industry-standard blur quality.

## Target User
Parents who want to protect their children's privacy on social media while still sharing family moments.

## Core Requirements

### MVP Features (Phase 1)
1. **Photo Selection**: Import photos from camera roll
2. **Drawing Interface**: Touch-based drawing to mark blur areas
3. **Selective Blur**: Apply professional-quality blur to drawn areas only
4. **Export/Share**: Save or share processed images
5. **Simple UI**: Clean, modern interface requiring minimal learning

### Core Features (Phase 1.5)
6. **Video Selection**: Import videos from camera roll
7. **Automatic Face Detection**: Use Vision framework to detect faces in videos
8. **Video Face Blur**: Apply real-time blur to detected faces throughout video
9. **Video Export**: Save processed videos to camera roll

### Technical Requirements
- **Platform**: iOS 15.0+
- **Framework**: SwiftUI + UIKit (for photo picker)
- **Blur Quality**: Industry-standard using Core Image filters
- **Performance**: Real-time drawing feedback, sub-2-second blur processing
- **File Support**: JPEG, HEIC, PNG from photo library; MP4, MOV from video library
- **Face Detection**: Vision framework for automatic face recognition in videos
- **Video Processing**: AVFoundation for video manipulation and export

## File Structure & Architecture

```
PhotoBlurApp/
├── PhotoBlurApp.xcodeproj
├── PhotoBlurApp/
│   ├── App/
│   │   ├── PhotoBlurApp.swift                 # Main App entry point
│   │   └── Info.plist                         # App configuration
│   │
│   ├── Views/
│   │   ├── ContentView.swift                  # Main coordinator view
│   │   ├── MediaSelectionView.swift           # Photo/Video selection screen
│   │   ├── EmptyStateView.swift              # Welcome/no media state
│   │   ├── PhotoEditView.swift               # Photo display + drawing overlay
│   │   ├── VideoEditView.swift               # Video display + face detection
│   │   ├── DrawingOverlay.swift              # Touch drawing interface
│   │   ├── VideoControlsView.swift           # Video playback controls
│   │   └── BottomControlsView.swift          # Action buttons
│   │
│   ├── Models/
│   │   ├── BlurPath.swift                    # Data model for drawn paths
│   │   ├── MediaType.swift                   # Enum for photo/video types
│   │   └── FaceDetectionResult.swift         # Face detection data
│   │
│   ├── Services/
│   │   ├── BlurProcessor.swift               # Core blur processing logic
│   │   ├── VideoFaceDetector.swift           # Vision-based face detection
│   │   ├── VideoBlurProcessor.swift          # Video blur processing
│   │   ├── MediaPicker.swift                 # Photo/Video library integration
│   │   └── VideoExporter.swift               # Video export functionality
│   │
│   ├── Utils/
│   │   ├── ShareSheet.swift                  # iOS share functionality
│   │   ├── PermissionsManager.swift          # Camera roll permissions
│   │   └── Extensions.swift                  # Utility extensions
│   │
│   └── Resources/
│       ├── Assets.xcassets                   # App icons, colors
│       └── Launch Screen.storyboard          # Launch screen
│
└── README.md                                 # Setup instructions
```

## Component Specifications

### 1. ContentView.swift
**Purpose**: Main app coordinator and state management
**Responsibilities**:
- Manage app-wide state (selected media, media type, blur paths, processed content)
- Handle view transitions and modal presentations
- Coordinate between photo and video editing modes

### 2. MediaSelectionView.swift
**Purpose**: Choose between photo and video processing
**Requirements**:
- Segmented control or tab interface for photo/video selection
- Launch appropriate media picker based on selection
- Clear visual distinction between modes

### 3. EmptyStateView.swift
**Purpose**: Initial welcome screen when no media is selected
**Requirements**:
- Clear call-to-action to select photo or video
- Modern, friendly design with system icons
- Buttons for both photo and video selection

### 4. PhotoEditView.swift
**Purpose**: Display selected photo with drawing capabilities
**Requirements**:
- Aspect-fit image display with proper scaling
- Overlay drawing interface when in drawing mode
- Accurate touch-to-image coordinate mapping
- Visual feedback for drawing areas (red lines)

### 5. VideoEditView.swift
**Purpose**: Display video with face detection and blur controls
**Requirements**:
- Video player with standard playback controls
- Real-time face detection overlay during playback
- Visual indicators for detected faces (colored rectangles)
- Toggle for automatic face blur on/off
- Preview of blur effect in real-time

### 6. DrawingOverlay.swift
**Purpose**: Handle touch input for marking blur areas (photos only)
**Technical Requirements**:
- Canvas-based drawing with smooth line rendering
- Convert screen coordinates to image pixel coordinates
- Real-time path visualization
- Support both single taps and continuous drawing

### 7. VideoControlsView.swift
**Purpose**: Video-specific playback and processing controls
**Requirements**:
- Play/pause button
- Scrub timeline for video navigation
- Face detection toggle
- Processing progress indicator
- Export button when processing complete

### 8. VideoFaceDetector.swift
**Purpose**: Detect faces in video frames using Vision framework
**Technical Requirements**:
- Use VNDetectFaceRectanglesRequest for face detection
- Process video frames at 30fps or video's native framerate
- Track faces across frames for consistent blur application
- Handle multiple faces per frame
- Optimize for real-time performance

### 9. VideoBlurProcessor.swift
**Purpose**: Apply blur effects to detected faces in video
**Technical Requirements**:
- Use AVVideoComposition for real-time video effects
- Apply Gaussian blur to face regions only
- Maintain blur consistency across frames
- Handle face tracking and movement
- Export processed video maintaining original quality and audio

### 10. VideoExporter.swift
**Purpose**: Export processed videos to camera roll
**Technical Requirements**:
- Use AVAssetExportSession for high-quality export
- Maintain original video resolution and framerate
- Preserve audio track
- Show export progress to user
- Handle export errors gracefully

## User Flow

### Photo Processing Flow
```
App Launch
    ↓
Media Selection (Photo/Video)
    ↓
Select Photo → Photo Edit View
    ↓
Toggle Drawing Mode → Draw on Image
    ↓
Apply Blur → Processed Image
    ↓
Share/Save → Export Options
```

### Video Processing Flow
```
App Launch
    ↓
Media Selection (Photo/Video)
    ↓
Select Video → Video Edit View
    ↓
Play Video → Faces Auto-Detected
    ↓
Toggle Face Blur → Preview Effect
    ↓
Process Video → Export Progress
    ↓
Share/Save → Export Options
```

## Technical Implementation Guidelines

### Drawing System
- Use SwiftUI Canvas for smooth drawing
- Store paths as arrays of CGPoints in image coordinates
- Convert between screen and image coordinates accurately
- Provide visual feedback with semi-transparent red overlay

### Blur Processing (Photos)
- Primary: Core Image CIFilter.gaussianBlur()
- Fallback: Custom pixel-level blending if CI fails
- Create binary masks from drawn paths (white = blur, black = original)
- Use brush width of 40-60 pixels for adequate coverage

### State Management
- Single source of truth in ContentView for both photos and videos
- Separate state management for photo editing vs video processing
- Pass state down via @Binding
- Clear state on media selection/reset
- Handle video playback state and face detection results

### Error Handling
- Graceful fallbacks for image/video processing failures
- User-friendly error messages for permission issues
- Handle video processing timeouts and memory constraints
- Maintain app stability with proper optionals and guards
- Clear error states for face detection failures

## UI/UX Requirements

### Design Principles
- **Minimal**: Focus on core functionality only
- **Intuitive**: No tutorials needed, obvious interactions
- **Modern**: Follow iOS design guidelines
- **Accessible**: Proper contrast, touch targets, labels

### Visual Style
- Clean backgrounds (white/light gray)
- System blue for primary actions
- Red overlay for drawing areas (semi-transparent)
- Rounded corners and modern button styles
- SF Symbols for icons

### Interaction Patterns
- Tap to select media type (photo/video)
- Tap to select specific media from library
- **Photos**: Toggle to enter drawing mode, draw directly on image
- **Videos**: Automatic face detection with visual overlay
- Single tap to apply blur/process video
- Standard iOS share sheet for export
- Video scrubbing and playback controls

## Future Enhancements (Post-MVP)

### Phase 2 Features
- **Photos**: Automatic face detection and blur for photos
- Adjustable blur intensity slider
- Different blur types (pixelate, mosaic)
- Undo/redo drawing actions
- Multiple brush sizes
- **Videos**: Manual face selection override
- Video trimming before processing
- Batch processing multiple videos

### Phase 3 Features
- Batch processing multiple photos/videos
- Custom blur shapes (circles, rectangles)
- Save drawing templates
- In-app photo/video capture
- Advanced face tracking and recognition
- Cloud processing for large videos

## Performance Requirements
- App launch: < 2 seconds
- Photo loading: < 1 second
- Video loading: < 3 seconds
- Drawing response: Real-time (60fps)
- Photo blur processing: < 2 seconds for 12MP images
- Video face detection: Real-time at 30fps
- Video processing: < 5 seconds per minute of 1080p video
- Memory usage: < 200MB for typical use, < 500MB for 4K video processing

## Quality Assurance

### Testing Requirements
- Test on various iPhone screen sizes and orientations
- Verify blur quality matches industry standards for both photos and videos
- Ensure drawing accuracy across different image orientations
- Test face detection accuracy across different lighting conditions and angles
- Validate video processing maintains audio sync and quality
- Test memory management with large images and 4K videos
- Validate share functionality across social platforms
- Test video export formats compatibility

### Code Quality Standards
- Swift 5.0+ with modern syntax
- SwiftUI best practices
- Proper error handling with do-catch blocks
- Memory-safe Core Image processing
- Clean separation of concerns

## Deployment Requirements
- iOS 15.0+ minimum deployment target
- Xcode 14+ for development
- No external dependencies (use system frameworks only)
- Proper Info.plist permissions for photo and video access
- Camera roll write permissions for video export

## Success Metrics
- **Functional**: Blur processing works 99.9% of the time for photos and videos
- **Performance**: Sub-2-second photo processing, sub-5-second per minute video processing
- **Accuracy**: Face detection accuracy >95% in good lighting conditions
- **Usability**: Users can complete blur task without instructions
- **Quality**: Blur effect indistinguishable from professional tools
- **Reliability**: Video export success rate >98%

## Development Notes for Cursor IDE

### Key Implementation Points
1. **Coordinate Mapping**: Critical to get drawing alignment correct for photos
2. **Face Detection**: Use Vision framework with VNDetectFaceRectanglesRequest for real-time detection
3. **Video Processing**: Leverage AVVideoComposition for efficient video blur effects
4. **Image Processing**: Use Core Image for quality, fallback for reliability  
5. **State Management**: Keep it simple with clear data flow between photo/video modes
6. **Error Handling**: Fail gracefully, never crash, especially during video processing
7. **Performance**: Profile both image and video processing on device
8. **Memory Management**: Critical for video processing - use autoreleasepool for frame processing

### Common Pitfalls to Avoid
- Screen vs image coordinate confusion in photo editing
- Memory leaks during video processing (use autoreleasepool)
- Force unwrapping optionals in image/video processing
- Complex state management between photo and video modes
- Over-engineering the drawing system
- Not handling video orientation changes
- Face detection performance issues on older devices
- Video export quality degradation
- Audio sync issues during video processing

### Required Permissions (Info.plist)
```xml
<key>NSPhotoLibraryUsageDescription</key>
<string>This app needs access to photos and videos to blur sensitive areas</string>

<key>NSPhotoLibraryAddUsageDescription</key>
<string>This app needs permission to save processed videos to your photo library</string>

<key>NSCameraUsageDescription</key>
<string>This app needs camera access for future photo/video capture features</string>
```

### Required Frameworks
- **SwiftUI**: Modern UI framework
- **AVFoundation**: Video processing and export
- **Vision**: Face detection in videos
- **Core Image**: Image and video blur effects
- **Photos**: Photo library access
- **PhotosUI**: Modern photo/video picker
